(function(e){function t(t){for(var o,a,s=t[0],c=t[1],p=t[2],d=0,g=[];d<s.length;d++)a=s[d],Object.prototype.hasOwnProperty.call(r,a)&&r[a]&&g.push(r[a][0]),r[a]=0;for(o in c)Object.prototype.hasOwnProperty.call(c,o)&&(e[o]=c[o]);l&&l(t);while(g.length)g.shift()();return i.push.apply(i,p||[]),n()}function n(){for(var e,t=0;t<i.length;t++){for(var n=i[t],o=!0,s=1;s<n.length;s++){var c=n[s];0!==r[c]&&(o=!1)}o&&(i.splice(t--,1),e=a(a.s=n[0]))}return e}var o={},r={app:0},i=[];function a(t){if(o[t])return o[t].exports;var n=o[t]={i:t,l:!1,exports:{}};return e[t].call(n.exports,n,n.exports,a),n.l=!0,n.exports}a.m=e,a.c=o,a.d=function(e,t,n){a.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},a.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},a.t=function(e,t){if(1&t&&(e=a(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(a.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)a.d(n,o,function(t){return e[t]}.bind(null,o));return n},a.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return a.d(t,"a",t),t},a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},a.p="";var s=window["webpackJsonp"]=window["webpackJsonp"]||[],c=s.push.bind(s);s.push=t,s=s.slice();for(var p=0;p<s.length;p++)t(s[p]);var l=c;i.push([0,"chunk-vendors"]),n()})({0:function(e,t,n){e.exports=n("cd49")},"09ea":function(e,t,n){},"0aa9":function(e,t,n){},"0ced":function(e,t,n){e.exports=n.p+"img/1.ff7e5f6e.png"},"0db5":function(e,t,n){e.exports=n.p+"img/0.b8a7d661.gif"},"19a8":function(e,t,n){"use strict";n("5c51")},"1bf1":function(e,t,n){"use strict";n("4076")},2064:function(e,t,n){},2155:function(e,t,n){e.exports=n.p+"img/NUS.e8930f16.jpg"},"22e7":function(e,t,n){var o={"./NUS.jpg":"2155","./TORONTO.jpg":"ccb7","./清华大学.jpg":"83a7","./香港科技大学.jpg":"c0ff"};function r(e){var t=i(e);return n(t)}function i(e){if(!n.o(o,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return o[e]}r.keys=function(){return Object.keys(o)},r.resolve=i,e.exports=r,r.id="22e7"},"2d4f":function(e,t,n){e.exports=n.p+"img/1.b8a7d661.gif"},"2e1b":function(e,t,n){"use strict";n("54f6")},"3a96":function(e,t,n){var o={"./0.png":"5fd6","./1.png":"0ced","./2.png":"714a","./x.png":"b976","./xx.png":"cfa2","./xxx.png":"4da8"};function r(e){var t=i(e);return n(t)}function i(e){if(!n.o(o,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return o[e]}r.keys=function(){return Object.keys(o)},r.resolve=i,e.exports=r,r.id="3a96"},4076:function(e,t,n){},4382:function(e,t,n){e.exports=n.p+"img/2.b8a7d661.gif"},"48d9":function(e,t,n){"use strict";n("7ca7")},"4da8":function(e,t,n){e.exports=n.p+"img/xxx.e4047474.png"},5022:function(e,t,n){},"508d":function(e,t,n){},"54f6":function(e,t,n){},"55a5":function(e,t,n){"use strict";n("e052")},"59a3":function(e,t,n){"use strict";n("508d")},"5c51":function(e,t,n){},"5db5":function(e,t,n){"use strict";n("6730")},"5fd6":function(e,t,n){e.exports=n.p+"img/0.d6279389.png"},"63bf":function(e,t,n){},6730:function(e,t,n){},"6d53":function(e,t,n){"use strict";n("a296")},"6e30":function(e,t,n){"use strict";n("ed26")},7037:function(e,t,n){},"714a":function(e,t,n){e.exports=n.p+"img/2.4f5481f0.png"},"74f3":function(e,t,n){},"767c":function(e,t,n){"use strict";n("5022")},"7ca7":function(e,t,n){},"7d49":function(e,t,n){"use strict";n("0aa9")},"83a7":function(e,t,n){e.exports=n.p+"img/清华大学.c111f20f.jpg"},"8e44":function(e,t,n){},"992f":function(e,t,n){"use strict";n("09ea")},a0cf:function(e,t,n){"use strict";n("8e44")},a296:function(e,t,n){},b47e:function(e,t,n){"use strict";n("74f3")},b976:function(e,t,n){e.exports=n.p+"img/x.bbfff928.png"},c0ff:function(e,t,n){e.exports=n.p+"img/香港科技大学.e64963c4.jpg"},cb2c:function(e,t,n){"use strict";n("2064")},ccb7:function(e,t,n){e.exports=n.p+"img/TORONTO.084008c3.jpg"},cd49:function(e,t,n){"use strict";n.r(t);var o=n("2b0e"),r=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{attrs:{id:"app"}},[t("Header"),t("div",{staticClass:"container href",attrs:{id:"Home"}},[t("Profile"),t("info-list"),t("NavigationBar"),t("New"),t("ResearchInterest"),t("Publication"),t("Projects"),t("Biography"),t("ProfessionalExperience"),t("Honors"),t("Patent"),t("SoftwareCopyrght"),t("ScientificFund"),t("Footer")],1)],1)},i=[],a=n("9ab4"),s=n("1b40"),c=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"header-wrapper"},[t("div",{staticClass:"content-wrapper"},[t("div",{staticClass:"left"},[t("div",{staticClass:"name"},[t("span",[e._v(e._s(e.words.name))])]),t("div",{staticClass:"blog"},[e._v(e._s(e.words.blog))])]),t("div",{staticClass:"right"},e._l(e.LanguageItems,(function(n,o){return t("div",{key:o,staticClass:"language-item",on:{click:()=>e.changeLanguage(n)}},[e._v(" "+e._s(n.__identity)+" ")])})),0)])])},p=[],l=n("4bb5");let d=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e])}changeLanguage(e){this.$store.dispatch("setLanguage",e.__langKey)}};Object(a["a"])([Object(s["b"])()],d.prototype,"msg",void 0),Object(a["a"])([Object(l["a"])("words")],d.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],d.prototype,"dictionary",void 0),d=Object(a["a"])([s["a"]],d);var g=d,h=g,u=(n("59a3"),n("2877")),f=Object(u["a"])(h,c,p,!1,null,"7eb63195",null),m=f.exports,w=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"info-list-wrapper"},[e._l(e.longInfoList,(function(n,o){return t("div",{key:o,staticClass:"long-info-list list-item"},[t("font-awesome-icon",{staticClass:"icon",attrs:{icon:n.icon}}),e._v(" "+e._s(n.msg)+" ")],1)})),t("div",{staticClass:"short-list-wrapper"},e._l(e.shortInfoList,(function(n,o){return t("div",{key:o,staticClass:"short-info-list list-item"},[t("font-awesome-icon",{staticClass:"icon",attrs:{icon:n.icon}}),e._v(" "+e._s(n.msg)+" ")],1)})),0),t("div",{staticClass:"icons"},e._l(e.icons,(function(n,o){return t("div",{key:o,staticClass:"icon"},[t("a",{staticStyle:{display:"block"},attrs:{href:n.href}},[t("font-awesome-icon",{staticClass:"icon",style:{color:n.hovTheme,backgroundColor:n.bgC},attrs:{icon:n.icon},on:{mouseenter:()=>e.setColor(n),mouseleave:()=>e.resetColor(n)}})],1)])})),0)],2)},b=[];let y=class extends s["c"]{constructor(){super(...arguments),this.icons=[{hovTheme:"#000",icon:["fab","github"],href:"https://github.com/lin-nie",theme:"lightseagreen"},{hovTheme:"#000",icon:["fab","linkedin"],href:"https://www.linkedin.com/in/nie-lin/",theme:"rgb(24, 119, 242)"},{hovTheme:"#000",icon:["fab","facebook-square"],href:"https://www.facebook.com/profile.php?id=100028198980924",theme:"rgb(59, 87, 157)"},{hovTheme:"#000",icon:["fab","twitter-square"],href:"https://twitter.com/NieLin6",theme:"rgb(59, 200, 244)"}]}created(){}get longInfoList(){return[{icon:["fas","home"],msg:this.words.address}]}get shortInfoList(){return[{icon:["fas","envelope"],msg:this.words.email},{icon:["fas","phone-alt"],msg:this.words.phone},{icon:["fas","tv"],msg:this.words.web}]}setColor(e){e.hovTheme=e.theme}resetColor(e){e.hovTheme="#000",e.bgC="#fff"}};Object(a["a"])([Object(l["a"])("words")],y.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],y.prototype,"dictionary",void 0),y=Object(a["a"])([s["a"]],y);var v=y,_=v,C=(n("55a5"),Object(u["a"])(_,w,b,!1,null,"f463fd1a",null)),P=C.exports,x=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"profile-wrapper"},[t("div",{staticClass:"profile-info-wrapper"},[e._m(0),t("div",{staticClass:"profile"},[t("h1",{staticClass:"name"},[e._v(" "+e._s(e.words.name)+" ")]),t("p",{staticClass:"advance-line"},[e._v(" "+e._s(e.words.degree)+" ")]),t("p",{staticClass:"advance-line"},[e._v(" "+e._s(e.words.major)+" ")]),t("p",{staticClass:"small-line"},[e._v(" "+e._s(e.words.academy)+" ")]),t("p",{staticClass:"small-line"},[e._v(" "+e._s(e.words.department)+" "),t("span",{staticStyle:{"font-weight":"600"}},[e._v(e._s(e.words.researchStudent))])]),t("hr",{staticStyle:{"margin-top":"10px"}}),t("div",{staticClass:"introduction"},[t("ul",{staticClass:"content"},[t("p",{domProps:{innerHTML:e._s(e.words.personalIntroduction)}}),t("p",{staticStyle:{"margin-top":"5px"}},[t("font",{attrs:{color:"red"},domProps:{innerHTML:e._s(e.words.notification)}}),t("br"),t("a",{attrs:{href:"http://www.linnie.com.cn/document/rp.pdf"}},[e._v(e._s(e.words.notificationSupp1))]),t("a",{attrs:{href:"http://www.linnie.com.cn/document/resume.pdf"}},[e._v(e._s(e.words.notificationSupp2))]),t("a",{attrs:{href:"http://www.linnie.com.cn/document/transcript.pdf"}},[e._v(e._s(e.words.notificationSupp4))]),t("a",{attrs:{href:"http://www.linnie.com.cn/project/egov/"}},[e._v(e._s(e.words.notificationSupp3))])],1)])])])]),t("div",{staticClass:"address-wrapper"}),e._m(1)])},j=[function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"profile-image"},[t("img",{attrs:{src:n("e429")}})])},function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"info-wrapper"},[t("div",{staticClass:"infos"}),t("div",{staticClass:"icons"})])}];let S=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],S.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],S.prototype,"dictionary",void 0),S=Object(a["a"])([s["a"]],S);var T=S,I=T,N=(n("1bf1"),Object(u["a"])(I,x,j,!1,null,"312d7884",null)),O=N.exports,H=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"navigation-wrapper"},[t("ul",[t("p",{staticClass:"name"},[e._v(e._s(e.words.navigation.name))]),e._l(e.words.navigation.address,(function(n,o){return t("li",[t("a",{staticClass:"menu-item",attrs:{href:"#"+e.href[o]}},[e._v(e._s(n))])])}))],2)])},A=[];let L=class extends s["c"]{constructor(){super(...arguments),this.href=["Home","New","Research Interest","Publication","Projects","Biography","Professional Experience","Honors","Patent","Software Copyrght","Fund Participation"]}get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],L.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],L.prototype,"dictionary",void 0),L=Object(a["a"])([s["a"]],L);var U=L,E=U,k=(n("992f"),Object(u["a"])(E,H,A,!1,null,"5a767f6d",null)),R=k.exports,V=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"new-wrapper wrapper-style href",attrs:{id:"New"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.newTitle)+" ")])])]),t("ul",{staticClass:"show-list"},[t("li",{domProps:{innerHTML:e._s(e.words.new.new20)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new19)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new18)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new17)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new16)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new15)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new14)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new13)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new12)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new11)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new10)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new9)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new8)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new7)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new6)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new5)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new4)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new3)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new2)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new1)}})])])},z=[];let M=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],M.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],M.prototype,"dictionary",void 0),M=Object(a["a"])([s["a"]],M);var F=M,D=F,G=(n("2e1b"),Object(u["a"])(D,V,z,!1,null,null,null)),K=G.exports,W=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"research-wrapper wrapper-style href",attrs:{id:"Research Interest"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.researchTitle)+" ")])])]),t("ul",{staticClass:"research-content"},[t("Strong",[e._v(e._s(e.words.overallField))]),t("br"),e._l(e.words.researchOverInterest,(function(n){return t("li",[e._v(" "+e._s(n)+" ")])})),t("br"),t("Strong",[e._v(e._s(e.words.specialField))]),t("br"),e._l(e.words.researchSpecialInterest,(function(n){return t("li",[e._v(" "+e._s(n)+" ")])}))],2)])},B=[];let Q=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],Q.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],Q.prototype,"dictionary",void 0),Q=Object(a["a"])([s["a"]],Q);var Z=Q,X=Z,Y=(n("b47e"),Object(u["a"])(X,W,B,!1,null,"f0a999b6",null)),J=Y.exports,$=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"publication"},[t("div",{staticClass:"conference-wrapper wrapper-style href",attrs:{id:"Publication"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.conferenceTitle)+" ")])])]),t("ul",{staticClass:"content"},e._l(e.words.conferencePublication,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("p",{domProps:{innerHTML:e._s(n.author)}}),e._v(" "+e._s(n.date)+" ")])})),0)])])},q=[];let ee=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],ee.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],ee.prototype,"dictionary",void 0),ee=Object(a["a"])([s["a"]],ee);var te=ee,ne=te,oe=(n("a0cf"),Object(u["a"])(ne,$,q,!1,null,"5a05382a",null)),re=oe.exports,ie=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"projects-wrapper wrapper-style href",attrs:{id:"Projects"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.projectsTitle)+" ")])])]),t("h4",[t("span",{staticStyle:{"background-color":"#ffffd0"}},[e._v(e._s(e.words.projectsHightLight))]),e._v(e._s(e.words.projectsNote)+" ")]),t("div",{staticStyle:{background:"#ffffd0"}},e._l(e.words.recentlyProjects,(function(o,r){return t("div",{staticClass:"project-component"},[t("div",{staticClass:"projects-img"},[t("a",{attrs:{href:"javascript:;"}},[t("img",{attrs:{src:n("d4d5")(`./${r}.gif`),alt:""}})])]),t("div",{staticClass:"content"},[t("strong",[e._v(e._s(o.name))]),t("p",{domProps:{innerHTML:e._s(o.author)}}),t("p",[e._v(e._s(o.match))]),t("p",[e._v(e._s(o.match2))]),0==r?t("div",[e._v(" "+e._s(o.paper)+" "+e._s(o.projectPage)+" "+e._s(o.code)+" "+e._s(o.video)+" ")]):e._e(),1==r?t("div",[t("a",{attrs:{href:"https://arxiv.org/pdf/2207.03095.pdf"}},[e._v(e._s(o.paper))]),e._v(" "+e._s(o.projectPage)+" "),t("a",{attrs:{href:"https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA"}},[e._v(e._s(o.code))]),e._v(" "+e._s(o.video)+" ")]):e._e(),2==r?t("div",[t("a",{attrs:{href:"https://arxiv.org/abs/2207.05409"}},[e._v(e._s(o.paper))]),t("a",{attrs:{href:"https://github.com/dzy3/KCD"}},[e._v(e._s(o.code))])]):e._e(),3==r?t("div",[e._v(" "+e._s(o.video)+" ")]):e._e(),e._l(o.label,(function(n){return t("span",{staticClass:"label"},[e._v(e._s(n))])}))],2)])})),0),e._l(e.words.pastProjects,(function(o,r){return t("div",{staticClass:"project-component"},[t("div",{staticClass:"projects-img"},[t("a",{attrs:{href:"javascript:;"}},[t("img",{attrs:{src:n("3a96")(`./${r}.png`),alt:""}})])]),t("div",{staticClass:"content"},[t("strong",[e._v(e._s(o.name))]),t("p",{domProps:{innerHTML:e._s(o.author)}}),t("p",[e._v(e._s(o.match))]),t("p",[e._v(e._s(o.match2))]),0==r?t("div",[t("a",{attrs:{href:"https://ieeexplore.ieee.org/document/9689024"}},[e._v(e._s(o.paper))]),e._v(" "+e._s(o.projectPage)+" "+e._s(o.code)+" "+e._s(o.video)+" ")]):e._e(),e._l(o.label,(function(n){return t("span",{staticClass:"label"},[e._v(e._s(n))])}))],2)])}))],2)},ae=[];let se=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],se.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],se.prototype,"dictionary",void 0),se=Object(a["a"])([s["a"]],se);var ce=se,pe=ce,le=(n("5db5"),Object(u["a"])(pe,ie,ae,!1,null,"4511d4fc",null)),de=le.exports,ge=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"biography-wrapper wrapper-style"},[t("div",[t("section",{staticClass:"title"},[t("h2",{staticClass:"href",attrs:{id:"Biography"}},[e._v(" "+e._s(e.words.biographyTitle)+" ")])])]),t("div",[t("p",{staticClass:"biography-content"},[e._v(" "+e._s(e.words.biography.bio1.introduce)+" "),t("a",{attrs:{href:"https://cai-mj.github.io/"}},[e._v(e._s(e.words.biography.bio1.mentor))]),t("br"),e._v(" "+e._s(e.words.biography.bio1.brief1)),t("br"),t("strong",[e._v(e._s(e.words.biography.bio1.brief2))])]),t("p",{staticClass:"biography-content"},[e._v(" "+e._s(e.words.biography.bio2.introduce)),t("br"),e._v(" "+e._s(e.words.biography.bio2.brief1)),t("br"),t("strong",[e._v(e._s(e.words.biography.bio2.brief2))])])])])},he=[];let ue=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],ue.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],ue.prototype,"dictionary",void 0),ue=Object(a["a"])([s["a"]],ue);var fe=ue,me=fe,we=(n("6e30"),Object(u["a"])(me,ge,he,!1,null,"1dc8f9c8",null)),be=we.exports,ye=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"experience-wrapper wrapper-style href",attrs:{id:"Professional Experience"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.exchangeTitle)+" ")])])]),t("div",{staticClass:"subtitle"},[t("strong",[e._v(e._s(e.words.exchangeSubtitle))])]),t("div",{staticClass:"img-box"},e._l(e.words.exchange,(function(o){return t("div",{staticClass:"exchange-img"},[t("img",{attrs:{src:n("22e7")(`./${o.imgName}.jpg`),alt:""}}),t("a",{attrs:{href:o.href}},[t("div",{staticClass:"mask-desc"},[t("div",{staticClass:"mask-content",domProps:{innerHTML:e._s(o.intro)}})])])])})),0),t("br"),t("div",[t("ul",e._l(e.words.profExprience,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("br"),e._v(" "+e._s(n.workplace)),t("span",{domProps:{innerHTML:e._s("              ")}}),e._v(e._s(n.topic)),t("br"),e._v(" "+e._s(n.title)+","+e._s(n.supervisor)+" ")])})),0)])])},ve=[];let _e=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],_e.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],_e.prototype,"dictionary",void 0),_e=Object(a["a"])([s["a"]],_e);var Ce=_e,Pe=Ce,xe=(n("cb2c"),Object(u["a"])(Pe,ye,ve,!1,null,"19165cb6",null)),je=xe.exports,Se=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"awards-wrapper wrapper-style href",attrs:{id:"Honors"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.awardsTitle)+" ")])])]),e._l(e.words.awards,(function(n){return t("ul",{staticClass:"awards-content"},[t("p",[e._v(e._s(e.words.scholarship))]),t("a",{attrs:{href:"http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html"}},[e._v(e._s(e.words.scholar1))]),e._v("   "+e._s(e.words.scholar1explain)),t("br"),t("i",[e._v(e._s(e.words.scholar1supp))]),t("br"),e._v(" "+e._s(e.words.scholar2)),t("br"),e._v(" "+e._s(e.words.scholar3)),t("br"),e._v(" "+e._s(e.words.scholar4)),t("br"),e._v(" "+e._s(e.words.scholar5)),t("br"),e._v(" "+e._s(e.words.scholar6)),t("br"),t("p",[e._v(e._s(n.subtitle))]),e._l(n.content,(function(n){return t("li",[e._v(e._s(n))])}))],2)}))],2)},Te=[];let Ie=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],Ie.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],Ie.prototype,"dictionary",void 0),Ie=Object(a["a"])([s["a"]],Ie);var Ne=Ie,Oe=Ne,He=(n("e471"),Object(u["a"])(Oe,Se,Te,!1,null,"60aafcf6",null)),Ae=He.exports,Le=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"publication"},[t("div",{staticClass:"patent-wrapper wrapper-style href",attrs:{id:"Patent"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.patentTitle)+" ")])])]),t("ul",{staticClass:"content"},e._l(e.words.patent,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("p",{domProps:{innerHTML:e._s(n.author)}}),t("p",{domProps:{innerHTML:e._s(n.number)}})])})),0)])])},Ue=[];let Ee=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],Ee.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],Ee.prototype,"dictionary",void 0),Ee=Object(a["a"])([s["a"]],Ee);var ke=Ee,Re=ke,Ve=(n("19a8"),Object(u["a"])(Re,Le,Ue,!1,null,"4b1834b5",null)),ze=Ve.exports,Me=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"copyrght-wrapper wrapper-style href",attrs:{id:"Software Copyrght"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.copyrghtTitle)+" ")])])]),t("ul",{staticClass:"copyrght-content"},e._l(e.words.softwareCopyrght,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("p",{domProps:{innerHTML:e._s(n.Number)}})])})),0)])},Fe=[];let De=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],De.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],De.prototype,"dictionary",void 0),De=Object(a["a"])([s["a"]],De);var Ge=De,Ke=Ge,We=(n("7d49"),Object(u["a"])(Ke,Me,Fe,!1,null,"47db2168",null)),Be=We.exports,Qe=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"tutorial-wrapper wrapper-style href",attrs:{id:"Fund Participation"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.scientificFundTitle)+" ")])])]),t("ul",{staticClass:"content"},e._l(e.words.scientificFund,(function(n){return t("li",[t("strong",{domProps:{innerHTML:e._s(n.name)}}),t("p",{domProps:{innerHTML:e._s(n.match)}})])})),0)])},Ze=[];let Xe=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],Xe.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],Xe.prototype,"dictionary",void 0),Xe=Object(a["a"])([s["a"]],Xe);var Ye=Xe,Je=Ye,$e=(n("767c"),Object(u["a"])(Je,Qe,Ze,!1,null,"429e83f7",null)),qe=$e.exports,et=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"footer-wrapper wrapper-style"},[t("p",[e._v(e._s(e.words.footer.period))]),t("p",{staticClass:"update"},[t("strong",[e._v(e._s(e.words.footer.lastUpdated))])])])},tt=[];let nt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(l["a"])("words")],nt.prototype,"words",void 0),Object(a["a"])([Object(l["b"])("dictionary")],nt.prototype,"dictionary",void 0),nt=Object(a["a"])([s["a"]],nt);var ot=nt,rt=ot,it=(n("48d9"),Object(u["a"])(rt,et,tt,!1,null,"c0cae402",null)),at=it.exports;let st=class extends s["c"]{};st=Object(a["a"])([Object(s["a"])({components:{Header:m,Profile:O,InfoList:P,NavigationBar:R,New:K,ResearchInterest:J,Publication:re,Projects:de,Biography:be,ProfessionalExperience:je,Honors:Ae,Patent:ze,SoftwareCopyrght:Be,ScientificFund:qe,Footer:at}})],st);var ct=st,pt=ct,lt=(n("6d53"),Object(u["a"])(pt,r,i,!1,null,null,null)),dt=lt.exports,gt=n("2f62");const ht={__identity:"English",__langKey:"en",name:"Nie Lin",degree:"Undergraduate Student (Graduate at 2022.06)",major:"Computer Science Software Engineering (GPA: 3.6+ Ranked: 1st/78 students)",academy:"Research Assistant",department:"College of Computer Science and Electronic Engineering, Hunan University ",researchStudent:"(Now)",personalIntroduction:'Hi! I am <strong>Nie Lin</strong>, an undergraduate student at the Dongguan University of Technology\n  in China, \n  and now I study at \n  <a href=\'http://www-en.hnu.edu.cn/index.htm\' target="_blank">\n  Hunan University</a>, supervised by \n  <a href=\'https://cai-mj.github.io/\' target="_blank">\n  Prof. Minjie Cai</a>. \n  <br>My research interests include \n  <strong>Computer Vision (CV)</strong>. \n  <strong>Especially in First-person Vision (FPV)</strong>, \n  <strong>Human-computer Interactions (HCI)</strong>, \n  I focus on\n  <strong>Human sensing and understanding <br>of human activities</strong>.\n  I have a strong interest in FPV research, welcome to \n  <a herf="mailto:nielin@hnu.edu.cn">\n  contact me</a>.',notification:"Currently, I am working on domain generalization for semantic segmentation and object detection. \n  I am looking for undergraduate or master students to engage in ongoing research papers. \n  Don't hesitate to email me if you are interested.",notificationSupp1:"[Research Proposal]",notificationSupp2:"[Curriculum Vitae]",notificationSupp3:"[Project Page]",notificationSupp4:"[Academic Transcripts]",address1:"Address1: Room 9A411 Institute of AI-Net Electronic Information & Artificial Intelligence, DGUT, Dongguan, China",address:"Address: Room 433 College of Computer Science and Electronic Engineering, Hunan University, Changsha, China (Now)",email:"Email: nielin@hnu.edu.cn",phone:"Phone: +86 131-3835-0137",web:"Web: linnie.com.cn",navigation:{name:"Nie Lin",address:["Home","New","Research Interest","Publication","Projects","Biography","Professional Experience","Honors","Patent","Software Copyrght","Fund Participation"]},newTitle:"New",new:{new1:"[ 2019.08 ] Under the leadership of Prof. Lvy Wang, I completed a research project on mathematics and machine learning in <Strong>University of Toronto, Canada</Strong>. Lay a mathematical foundation for my future research in <Strong>Computer Vision</Strong>.",new2:"[ 2019.12 ] I won 2019 year's <Strong>The First Prize Scholarship</Strong> for being the first in my grade. Thanks!",new3:"[ 2020.03 ] During the winter vacation, I worked as a research intern under the guidance of Prof. Qing Liao from <Strong>Harbin Institute of Technology (HIT)</Strong> to complete the project of <Strong>video understanding and analysis</Strong> through deep learning.",new4:"[ 2020.08 ] I completed my exchange programme study in the field of <Strong>Artificial Intelligence and Deep Learning</Strong> in the <Strong>National University of Singapore</Strong>. And won the <Strong>Honorary Award of the National University of Singapore</Strong>.",new5:"[ 2020.09 ] Congratulations, I successfully joined the <Strong>Institute of Industrial Artificial Intelligence Technology (IIAIT)</Strong> in Songshan Lake, Dongguan through multiple selection, and was supervised by <Strong>Prof. Gao Chen from Tsinghua University</Strong>.",new6:"[ 2020.10 ] I got The Third prize of China Artificial Intelligence Electronic Design Competition. Congratulations !!",new7:"[ 2020.12 ] I won 2020 year's <Strong>The First Prize Scholarship</Strong> and <Strong>The Kao Wei-kwong Enterprise Scholarship (Outstanding Engineering Representative) </Strong> for being the first in my grade. Thanks!",new8:"[ 2021.01 ] Our team successfully entered the <a href='https://www.ccf.org.cn/en/'>China Computer Federation (CCF) </a> <Strong>Artificial Intelligence Vision Algorithm Competition</Strong> and final with the rank of <Strong>13/2207</Strong>. A great team work experience !!",new9:"[ 2021.05 ] I won the <Strong>international second prize</Strong> in the American Mathematical Contest In Modeling (USA MCM). <a>[Project]</a>",new10:"[ 2021.06 ] Started research working as a <Strong>Research Assistant</Strong> at FPV Lab, Hunan University. Supervised by Prof. <a href='https://cai-mj.github.io/'>Minjie Cai</a>",new11:"[ 2021.10 ] I got my own <Strong>head-mounted camera</Strong> from our laboratory and will be trying to collect the first-person dataset in the future. Thanks!",new12:"[ 2021.12 ] I won 2021 year's <Strong>The First Prize Scholarship</Strong> and <Strong>The Lingnan Academic Scholarship (Outstanding Academic Representative) </Strong> for being the first in my grade. Thanks!",new13:"[ 2022.05 ] Congratulations! I won the <a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>National Scholarship of the People's Republic of China</a>, issued by the <a href='http://en.moe.gov.cn/'>Ministry of Education of China</a>, which is the highest level scholarship program in China! (<Strong>TOP 0.01% Students in China</Strong>).",new14:'[ 2022.06 ] My graduation thesis <Strong>"First-person Action Recognition Based on Unsupervised Domain Adaptation in Egocentric Video"</Strong> successfully pass the thesis defense of undergraduate graduation design.',new15:'[ 2022.06 ] Congratulations! I successfully graduated from <a herf="">DGUT Computer Software Engineering</a> with <strong>the first place</strong> in my major (<strong>Rank 1st / 78</strong> ) with a <a>Bachelor of Engineering degree</a>. And won the <Strong>Outstanding Undergraduate Graduate</Strong>',new16:'[ 2022.06 ] Congratulations! My paper on <a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC22</a> about <Strong>UDA Frist-person Action Recognition</Strong> has been successfully accepted, under the supervision of Prof. <a href="https://cai-mj.github.io/">Minjie Cai</a>. The arXiv and code is available. <a href="https://arxiv.org/abs/2207.03095">[ArXiv]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github Code]</a>',new17:'[ 2022.07 ] I was invited to attend this year\'s <a href="https://cvpr2022.thecvf.com/">CVPR 22</a> and participate in the <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 22</a> presentation. <a>Here</a> is the description.',new18:'[ 2022.07 ] Our paper on <Strong>Knowledge Transfer Learning</Strong> has been accepted for <Strong>ECCV 22</Strong>!! Code is available. <a href="https://github.com/dzy3/KCD">[Github Code]</a>',new19:'[ 2022.08 ] Under the guidance of Prof. <a href="https://cai-mj.github.io/">Minjie Cai</a>, I submitted a paper at <Strong>BMVC 2022</Strong> this year based on <Strong>hand regions in egocentric videos related to first-personaction recognition</Strong>. Code will be open source !!',new20:'[ 2022.09 ] I really hope that I can apply for a research student and master as soon as possible to start my new project: <Strong>EgoV: From Virtual to Real </Strong>. <a href="https://github.com/dzy3/KCD">[Github Code]</a><a href="https://github.com/dzy3/KCD">[Project Page]</a><a href="https://github.com/dzy3/KCD">[Research Proposal]</a>'},biographyTitle:"Biography",biography:{bio1:{introduce:"(2021.6 - Now) Research Assistant. Supervised by Prof.",mentor:"Minjie Cai",brief1:"College of Computer Science and Electronic Engineering, FPV Lab",brief2:"Hunan University"},bio2:{introduce:"(2018.9 - 2022.6) BSc in Computer Science & Software Engineering (Graduate at 2022.06)",brief1:"Institute of Industrial Artificial Intelligence Technology (IIAIT)",brief2:"Dongguan University of Technology"}},exchangeTitle:"Professional Experience",exchangeSubtitle:"I am very keen on scientific research exchange，the following are the Universities where I often communicate and study :",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              Tsinghua University\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.17 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.28 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.20 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: No.29 in the world University Rankings\n              </p>\n               '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              National University of Singapore\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.11 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.32 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.25 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              University of Toronto\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.26 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.17 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.18 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: No.23 in the world University Rankings\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              Hong Kong University of Science and Technology\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.34 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.109 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.56 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. Hunan University (HNU)",workplace:"Changsha, China",topic:"Topic: First-person Action Recognition base on Hand Region",title:"Research Assistant",supervisor:" Supervisor: Prof. Minjie Cai [Hunan University]"},{name:"2. Institute of Industrial Artificial Intelligence Technology (IIAIT)",workplace:"Dongguan, China",topic:"Topic: Digital Image Processing",title:"Research Assistant",supervisor:" Supervisor: Prof. Gao Chen [Tsinghua University]"},{name:"3. Harbin Institute of Technology (HIT)",workplace:"Shenzhen, China",topic:"Topic: Video Analysis and Understanding",title:"Research Intern",supervisor:" Supervisor: Prof. Qing Liao [Harbin Institute of Technology]"},{name:"4. University of Toronto (UofT)",workplace:"Toronto, Canada",topic:"Topic: Mathematics and Machine Learning",title:"Project Student",supervisor:" Supervisor: Prof. Lvy Wang [University of Toronto]"}],researchTitle:"Research Interest",overallField:"Overall Field",researchOverInterest:["Computer Vision (CV)","First-person Vision (FPV)","Human-computer Interactions (HCI),"],specialField:"Special Interests",researchSpecialInterest:["1. Egocentric Video Understanding and Analysis","2. Domain Adaptation & Generalization","3. Action Recognition","4. Hand Region Analysis","5. Knowledge Transfer Learning",".........................."],awardsTitle:"Honors",scholarship:"Scholarship",scholar1:"1. National Scholarship of the People's Republic of China",scholar1explain:"[Ministry of Education of China]",scholar1supp:"(TOP 0.1% Students in China)",scholar2:"2. The Lingnan Academic Scholarship  [Outstanding Academic Representative]",scholar3:"3. The First Prize Scholarship   [The First Place of GPA in the Grade, 2021]",scholar4:"4. The Kao Wei-kwong Enterprise Scholarship   [Outstanding Engineering Representative]",scholar5:"5. The First Prize Scholarship   [The First Place of GPA in the Grade, 2020]",scholar6:"6. The First Prize Scholarship   [The First Place of GPA in the Grade, 2019]",awards:[{subtitle:"Awards",content:["Outstanding Undergraduate of Guangdong Province","Outstanding Undergraduate's Thesis","International Second Prize in the American Mathematical Contest In Modeling","China Computer Federation AI Vision Algorithm Competition (Rank 13/2207)","The Third prize of China Artificial Intelligence Electronic Design Competition","Honorary Award of the National University of Singapore","Excellent Huawei Developer Award"]}],conferenceTitle:"Publication",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022: Team HNU-FPV Report",author:'<a href="#">Nie Lin</a>, Minjie Cai*',date:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshop, 2022",arixv:"xxxx",code:"xxxxx"},{name:"Knowledge Condensation Distillation",author:'Chenxin Li, Mingbao Lin, Zhiyuan Ding, <a href="#">Nie Lin</a>, Yihong Zhuang, Yue Huang*',date:"European Conference on Computer Vision (ECCV), 2022",arixv:"xxxx",code:"xxxxx"}],journalTitle:"Journal Publication",journalPublication:[{}],patentTitle:"Patent",patent:[{name:"Human-computer Interaction (HCI) Sensing Devices based on Analog Signal Processing",author:'<a href="">Nie Lin</a>, Chanzhi Liu, Haofeng Li, Shihao Zou, Junyu Li, Ruofan Hu',number:"CN 202022246705.5"}],copyrghtTitle:"Software Copyrght",softwareCopyrght:[{name:"OCR Recognition System for Japanese Postal Payment Notes",Number:"No.A0003976 in SoftwareCopyright"},{name:"Video copyright protection system based on artificial intelligence",Number:"No.4840268 in SoftwareCopyright"}],projectsTitle:"Projects",projectsHightLight:"Highlighted",projectsNote:" projects are recently projects.",recentlyProjects:[{name:"EgoV: A New Datasets of Egocentric Videos Across Real and Virtual",author:"<strong>!! As a new long-term research project will be carried out at the master's level !!</strong>",match:"",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"UDA First-person Action Recognition based on Hand Regions in Egocentric Videos",author:"<strong>Nie Lin</strong>, Minjie Cai",match:"Hunan University",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"Knowledge Condensation Distillation base on Transfer Learning",author:"Chenxin Li, Mingbao Lin, <strong>Nie Lin</strong>, Yihong Zhuang, Yue Huang",match:"Xiamen & Hunan University, Tencent Youtu Lab",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"Dataset Acquisition from First-person Perspective (Through Head-mounted Camera)",author:"<strong>Nie Lin</strong>, Minjie Cai",match:"Hunan University",paper:"",projectPage:"",code:"",video:"[Video]"}],pastProjects:[{name:"Dilated Residual Shrinkage Network for Digital Image Despeckling",author:"<strong>Nie Lin</strong>, Gao Chen, Qingfeng Zhou, Chanzi Liu",match:"Institute of Industrial Artificial Intelligence Technology (IIAIT)",match2:"",paper:"[Paper]",projectPage:"",code:"",video:""},{name:"Multi-Modal Video Analysis and Understanding",author:"<strong>Nie Lin</strong>, Fan Guo, Jie Wang, Ye Ding, Qing Liao",match:"Harbin Institute of Technology (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"Hand-ball Action Recognition Control System based on OpenMV Machine Vision",author:"<strong>Nie Lin</strong>, Bing Wang, Qingfeng Zhou",match:"China Artificial Intelligence Electronic Design Competition",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"Fund Participation",scientificFund:[{name:'<a href="https://www.nsfc.gov.cn/english/site_1/index.html">The National Natural Science Foundation of China</a>',match:"No. 61971138 in the Scientific Fund"},{name:"Basic and Applied Basic Research Project of Guangdong Province under Grant",match:"No. 2019A1515111149 in the Scientific Fund"},{name:"Guangdong Higher Education Innovation and College Development Project",match:"No. 2020ZDZX3047 in the Scientific Fund"}],footer:{period:"© 2018 - 2022   Nie Lin",lastUpdated:"Last updated: July 31,2022"}};var ut=ht;const ft={__identity:"日本語",__langKey:"jp",name:"林 涅（リン ネエ）",degree:"学部学生 (卒業は2022年6月)",major:"コンピューター ソフトウェア工学 (GPA: 3.6+ ランキング: 専攻 1st/78 位)",academy:"助手研究員",department:"情報科学工学部, 湖南大学",researchStudent:"(いま)",personalIntroduction:'Hi，私は<strong>林 涅</strong>です，中国から学部学生です。今東莞理工大学に通っています ソフトウェア工学を専攻し。\n  私は\n  <a href="http://www-en.hnu.edu.cn/index.htm" target="_blank">\n  湖南大学</a>\n  で研究と勉強をしています、指導先生は\n  <a href="https://cai-mj.github.io/" target="_blank">\n  蔡敏捷</a>\n  教授です。\n  <br>私の研究の趣味は\n  <strong>コンピュータビジョン(CV)</strong>、\n  特に<strong>一人称視点映像解析(FPV)</strong> と\n  <strong>コンピュータグラフィック(CG)</strong>、\n  <strong>ヒューマンコンピュータインタラクション(HCI)</strong>\n  スに関するテーマです。私は<strong>一人称視点映像解析研究</strong>に深い興味を持っていて、交流することを歓迎します。\n  ',notification:"XXX",address1:"アドレス1: 中国広東省東莞市 DGUT-9A411 Ai-Net電子情報&人工知能研究所",address:"アドレス: 中国湖南省長沙市 湖南大学 情報科学及び工程学院研究生弁公室433 (いま)",email:"メールアドレス: nielin@hnu.edu.cn",phone:"電話番号: +86 131-3835-0137",web:"ホームページ: linnie.com.cn",newTitle:"ニュース",navigation:{name:"リン ネエ",address:["ホームページ","ニュース","研究興味","発表論文","プロジェクト","バイオグラフィー","専門経験","栄誉受賞","発明特许","ソフトウエア著作権","研究ファンド"]},new:{new1:"[ 2019.08 ] Prof. Lvy Wangの指導の下、<strong>カナダのトロント大学（UofT）</strong>で数学と機械学習に関する研究プロジェクトを行いました。<strong>コンピュータビジョン</strong>についての数学的な基礎を築きました。",new2:"[ 2019.12 ] 私は学年トップの優秀な成績で2019年度の<strong>一等奨学金</strong>を獲得しました。ありがとうございます!",new3:"[ 2020.03 ] 二年生の冬休みの間、私は<strong>ハルビン工業大学（HIT）のProf. Liaoの指導の下、研究実習に参加し、ディープ・ラーニングを通じて<strong>ビデオの理解と分析</strong>プロジェクトを完成させた。",new4:"[ 2020.08 ] 私は<strong>シンガポール国立大学（NUS）</strong>で<strong>人工知能とディープラーニング</strong>分野のプロジェクト学習を終えました。<strong>シンガポール国立大学版より栄誉賞</strong>を受賞。",new5:"[ 2020.09 ] おめでとうございます。私は選抜を経て<strong>工業人工知能技術研究院(IIAIT)</strong>に加入し、<strong>清華大学</strong>の陳高教授の指導でデジタル画像処理に関する研究を展開します。",new6:"[ 2020.10 ] 人工知能電子デザインコンテストで三等賞を受賞しました !!",new7:"[ 2020.12 ] 私は学年トップの優秀な成績で2020年の<strong>一等奨学金</strong>および<strong>高偉光企業奨学金(傑出工程代表)</strong>を獲得しました。ありがとうございます！",new8:'[ 2021.01 ] 私たちのチームは13/2207分の1に<判断> < /判断>のランキングに< aきゃ= " https://www.ccf.org.cn/en/ " >中国のコンピューター学会(ccf) < / a > <判断>人工知能視覚アルゴリズム大会決勝< /判断>。素晴らしいチームワーク体験でした!!',new9:'[ 2021.05 ] アメリカ数学モデリングコンテストUSA MCM/ICMで<Strong>国際二等賞</Strong>を受賞しました. <a href="#">[プロジェクト]</a>',new10:'[ 2021.06 ] 湖南大学のFPV実験室で<strong>研究アシスタント</strong>を始めました。<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授がインストラクターを務めます。',new11:"[ 2021.10 ] 私の研究室から自分の<Strong>ヘッドセット・カメラ</Strong>を入手し、将来的には一人称データセットの収集を試みます。ありがとうございます。",new12:"[ 2021.12 ] 私は学年トップの優秀な成績で2021年の<strong>一等奨学金</strong>、<strong>嶺南学術奨学金(優秀学術代表)</strong>を獲得しました。ありがとうございます!!",new13:"[ 2022.05 ] 恭喜! 我获得了<a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>中华人民共和国国家奖学金</a>, 由<a href='http://en.moe.gov.cn/'>中华人民共和国教育部</a>颁布, 这是中国最高级别的奖学金项目! (<Strong>全国排名前0.01%的学生</Strong>).",new14:"[ 2022.06 ] 私の卒業論文<strong>「自己中心的動画における無監督領域適応による一人称動作認識」</strong>は、学部の卒業設計論文の回答を無事通過しました。",new15:"[ 2022.06 ] おめでとうございます。私は<strong>専門の第一位(<strong>Rank 1st / 78</strong>)で<a>工学学士</a>を取得し、そして順調に<a>東莞理工コンピュータソフトウェア工程専門</a>を卒業しました。<strong>優秀学部卒業生</strong>を獲得。",new16:'[ 2022.06 ] おめでとうございます! 私の論文は<a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC22</a>で<Strong>無監督ドメイン適応について一人称動作認識</Strong>がスムーズに受信され, 在<a href="https://cai-mj.github.io/"蔡 敏捷</a>教授的指导下. 预印本和代码均可用. <a href="https://arxiv.org/abs/2207.03095">[ArXiv 预印本]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github代码]</a>',new17:'[ 2022.07 ] 我受邀参加今年<a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> 并参与 <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a> 演讲。<a>此处</a> 有相关描述.',new18:'[ 2022.07 ] 我们关于<Strong>知识迁移学习</Strong>的论文已经被今年的<Strong>ECCV 2022</Strong>正式接受!! 代码已经开源. <a href="https://github.com/dzy3/KCD">[Github 代码]</a>',new19:'[ 2022.08 ] 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下，我在今年的<Strong>BMVC 2022</Strong>上提交了一篇<Strong>基于自我中心视频中手部区域与第一人称动作识别相关的</Strong>论文。代码将会开源！！',new20:'[ 2022.08 ] 我非常希望我能尽快申请研究生和硕士，开始我的新项目:<Strong>EgoV: 从虚拟到现实</Strong>. <a href="https://github.com/dzy3/KCD">[Github Code]</a><a href="https://github.com/dzy3/KCD">[Project Page]</a><a href="https://github.com/dzy3/KCD">[Research Proposal]</a>'},biographyTitle:"バイオグラフィー",biography:{bio1:{introduce:"(2021.6-至今)  助手研究員. 指導教員は准教授",mentor:"蔡 敏捷",brief1:"情報科学及び工程學院, FPV Lab",brief2:"湖南大學"},bio2:{introduce:"(2018-至今)  コンピューター ソフトウェア工学 (卒業は2022年6月)",brief1:"産業用人工知能技術研究所 (IIAIT)",brief2:"東莞理工大學"}},exchangeTitle:"専門経験",exchangeSubtitle:"私は非常に科学研究の交流に熱心です、以下はよく交流して勉強している大学です：",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              清華大学\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.17\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.28\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.20\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: 世界大学のランキングーーNo.29\n              </p>\n                '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              シンガポール国立大学（NUS）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.11\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.32\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.25\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              トロント大学（UofT）\n              </p> \n              <br><p style="font-size: 14.9px">\n              QS 2021: 世界大学のランキングーーNo.26\n              </p>\n              <br><p style="font-size: 14.9px">\n              U.S. New : 世界大学のランキングーーNo.17\n              </p>\n              <br><p style="font-size: 14.9px">\n              THE 2021: 世界大学のランキングーーNo.18\n              </p>\n              <br><p style="font-size: 14.9px">\n              ARWU 2021: 世界大学のランキングーーNo.23\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              ホンコン科技大学（HKUST）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.34\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.109\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.56\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. 湖南大学 (HNU)",workplace:"長沙, 中国",topic:"研究テーマ: 手部領域に基づく一人称働作認識",title:"助手研究員",supervisor:" 指導教授: 蔡 敏捷 教授 [湖南大学]"},{name:"2. 工业人工智能技术研究所 (IIAIT)",workplace:"东莞, 中国",topic:"研究课题: 数字图像处理",title:"助理研究员",supervisor:" 指导教授: 陈高教授 [清华大学]"},{name:"3. 哈尔滨工业大学 (HIT)",workplace:"深圳, 中国",topic:"研究课题: 视频分析与理解",title:"研究实习生",supervisor:" 指导教授: 廖清教授 [哈尔滨工业大学(深圳)]"},{name:"4. 多伦多大学 (UofT)",workplace:"多伦多, 加拿大",topic:"研究课题: 数学与机器学习",title:"项目学生",supervisor:" 指导教授: Lvy Wang教授 [多伦多大学]"}],researchTitle:"研究興味",overallField:"Overall Field",researchOverInterest:["コンピュータビジョン (CV)","一人称視覚 (FPV)","ヒューマンコンピュータインタラクション (HCI),"],specialField:"Special Interests",researchSpecialInterest:["1. 自己中心的なビデオ理解と分析","2. ドメイン適応と一般化","3. 行動認識","4. 手部区域解析","5. 知識移動学習",".........................."],awardsTitle:"栄誉受賞",scholarship:"受けた奨学金",scholar1:"1. 中華人民共和国国家奨学金",scholar1explain:"[中華人民共和国教育部]",scholar1supp:"(中国の上位0.1%の学生)",scholar2:"2. 嶺南学術奨学金  [傑出した学術の代表]",scholar3:"3. 2021年度 一等奨学金   [学年GPA 1位、2021年]",scholar4:"4. 高偉光企業奨学金   [傑出した工事の代表]",scholar5:"5. 2020年度 一等奨学金   [学年GPA 1位、2020年]",scholar6:"6. 2019度 一等奨学金   [学年GPA 1位、2019年]",awards:[{subtitle:"受赏",content:["広東省の優秀な学部卒業生","優秀な学部生の論文","米国数学モデリングコンテスト国際2位","中国コンピュータ学会AI視覚アルゴリズム大会 (順位13/2207)","中国人工知能電子デザインコンテスト3等賞","シンガポール国立大学名誉賞","ファーウェイ優秀開発者賞"]}],conferenceTitle:"発表論文",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022: Team HNU-FPV Report",author:'<a href="#">Nie Lin</a>, Minjie Cai*',date:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshop, 2022",arixv:"xxxx",code:"xxxxx"},{name:"Knowledge Condensation Distillation",author:'Chenxin Li, Mingbao Lin, Zhiyuan Ding, <a href="#">Nie Lin</a>, Yihong Zhuang, Yue Huang*',date:"European Conference on Computer Vision (ECCV), 2022",arixv:"xxxx",code:"xxxxx"}],journalTitle:"ジャーナル論文",journalPublication:[{name:"暂無"}],patentTitle:"発明特许",patent:[{name:"アナログ信号処理ベースのヒューマンインタラクション感知装置",author:'<a href="#">林 涅</a>、劉 嬋梓、黎 浩鋒、鄒 世豪、李 俊裕',number:"CN 202022246705.5"}],copyrghtTitle:"ソフトウエア著作権",softwareCopyrght:[{name:"日本郵便の支払伝票OCR認識システム",Number:"ソフトウエア著作権 No.A0003976"},{name:"人工知能による映像著作権保護システム",Number:"ソフトウエア著作権 No.4840268"}],projectsTitle:"プロジェクト",projectsHightLight:"Highlighted",projectsNote:" は最近取り組んだプロジェクトについて言及した。",recentlyProjects:[{name:"EgoV: リアルとバーチャルの自己中心的なビデオの全く新しいデータセットです",author:"<strong>!! 新しい長期プロジェクトとして修士課程で始めます !!</strong>",match:"",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"自己中心ビデオの手領域に基づく監督のない領域適応一人称動作認識",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"移動学習による知識濃縮蒸留",author:"李 宸鑫, 林 明寶, <strong>林 涅</strong>, 莊 毅鴻, 黃 悅",match:"廈門大学 & 湖南大学",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"一人称視点でのデータ収集 (ヘッドマウントカメラによる)",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",paper:"",projectPage:"",code:"",video:"[Video]"}],pastProjects:[{name:"拡張残差縮小ネットワークによるデジタル画像ノイズ除去",author:"<strong>林 涅</strong>, 陳 高, 周 清峰, 劉 嬋梓",match:"産業用人工知能技術研究所 (IIAIT)",match2:"",paper:"[Paper]",projectPage:"",code:"",video:""},{name:"マルチモダリティ ビデオ分析と理解",author:"<strong>林 涅</strong>, 郭 凡, 王 傑, 丁 燁, 廖 清",match:"ハルビン工業大学 (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"OpenMVマシンビジョンによる ハン-ドボール 動作認識制御システム",author:"<strong>林 涅</strong>, 王 斌, 周 清峰",match:"中国人工知能電子デザインコンテスト",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"研究ファンド",scientificFund:[{name:'<a href="#">国家自然科学ファンド</a>',match:"国家自然科学ファンド号：No. 61971138"},{name:"広東省基礎と応用基礎研究助成プロジェクト",match:"项目基金号：No. 2019A1515111149"},{name:"広東省高等教育イノベーションと高校発展プロジェクト",match:"工程基金号：No. 2020ZDZX3047"}],footer:{period:"© 2018 - 2021  リン ネエ",lastUpdated:"前回のアップデート: 2021年8月16日"}};var mt=ft;const wt={__identity:"中文",__langKey:"zh",name:"林 涅",degree:"本科生 (毕业于 2022.06)",major:"计算机 & 软件工程专业 (GPA: 3.6+ 排名: 专业 第1st/78 名)",academy:"助理研究员",department:"信息科学与工程学院, 湖南大学",researchStudent:"（现在）",personalIntroduction:'Hi! 我叫<strong>林涅</strong>，是来自中国东莞理工大学的一名本科生。我现在正在\n  <a href="https://www.hnu.edu.cn/" target="_blank">\n  湖南大学</a>\n  学习，\n  <br>同时指导我学术科研的导师是\n  <a href="http://csee.hnu.edu.cn/people/caiminjie" target="_blank">\n  蔡敏捷</a>\n  教授。\n  <br>我的研究兴趣包括<strong>计算机视觉(CV)</strong>，特别是在<strong>第一人称视觉(FPV)</strong> 以及<strong>人机交互(HCI)</strong>，\n  特别是计算机视觉应用在<strong>感知和理解与人类相关的活动</strong>的领域。\n  我对计算机视觉中的第一人称视觉有着浓厚的兴趣与爱好，欢迎各位通过我的邮箱与我联系与交流。',notification:"XXX",address1:"地址1: 中国广东省东莞市松山湖 东莞理工大学 Ai-Net智能研究所 9A-411",address:"地址: 中国湖南省长沙市湖南大学 信息科学与工程学院 研究生办公室433 （现在）",email:"个人邮箱: nielin@hnu.edu.cn",phone:"个人电话: +86 131-3835-0137",web:"个人网站: linnie.com.cn",newTitle:"消息",navigation:{name:"林涅",address:["主页","消息","研究兴趣","论文发表","项目经验","个人经历","专业经验","荣誉奖项","发表专利","软件著作","参与基金"]},new:{new1:"[ 2019.08 ] 在Prof. Lvy Wang的指导下，我在<strong>加拿大多伦多大学</strong>完成了一个关于数学与机器学习的研究项目。为我以后关于<strong>计算机视觉</strong>的研究奠定数学基础。",new2:"[ 2019.12 ] 我以年级第一的优异成绩获得了2019年的<strong>一等奖学金</strong>。谢谢!",new3:"[ 2020.03 ] 在大二寒假期间，我在<strong>哈尔滨工业大学（深圳）</strong>廖教授的指导下参与研究实习，通过深度学习完成关于<strong>视频理解与分析</strong>项目。",new4:"[ 2020.08 ] 我在<strong>新加坡国立大学</strong>完成了<strong>人工智能与深度学习</strong>领域的项目学习。并获得由新加坡国立大学版发的<strong>荣誉奖</strong>。",new5:"[ 2020.09 ] 恭喜，我通过层层选拔加入<strong>工业人工智能技术研究院(IIAIT)</strong>，并由来自<strong>清华大学</strong>的陈高教授指导展开关于数字图像处理方面的研究。",new6:"[ 2020.10 ] 我获得中国人工智能电子设计大赛三等奖 !!",new7:"[ 2020.12 ] 我以年级第一的优异成绩获得了2020年的<Strong>一等奖学金</Strong>以及<Strong> 高伟光企业奖学金(杰出工程代表) </Strong>。谢谢!",new8:'[ 2021.01 ] 我们团队以<Strong>13/2207</Strong>的排名进入<a href="https://www.ccf.org.cn/en/">中国计算机学会(CCF) </a> <Strong>人工智能视觉算法大赛</Strong>决赛。一次很赞的团队合作体验!!',new9:"[ 2021.05 ] 我在美国数学建模竞赛USA MCM/ICM 中获得<Strong>国际二等奖</Strong>。<a>[项目]</a>",new10:"[ 2021.06 ] 开始在湖南大学的FPV实验室担任 <Strong>研究助理</Strong>。 由<a href='https://cai-mj.github.io/'>蔡 敏捷</a>教授担任指导老师。",new11:"[ 2021.10 ] 我从我们的实验室得到了属于我自己的<Strong>头戴式相机</Strong>，未来将尝试收集第一人称数据集。谢谢!",new12:"[ 2021.12 ] 我以年级第一的优异成绩获得了2021年的<Strong>一等奖奖学金</Strong>、<Strong>岭南学术奖学金(优秀学术代表)</Strong>，谢谢!",new13:"[ 2022.05 ] 恭喜! 我获得了<a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>中华人民共和国国家奖学金</a>, 由<a href='http://en.moe.gov.cn/'>中华人民共和国教育部</a>颁布, 这是中国最高级别的奖学金项目! (<Strong>全国排名前0.01%的学生</Strong>).",new14:"[ 2022.06 ] 我的毕业论文<strong>《基于自我中心视频中无监督域适应的第一人称动作识别》</strong>顺利通过了本科毕业设计论文答辩。",new15:"[ 2022.06 ] 恭喜! 我以<strong>专业第一名</strong>(<strong>Rank 1st / 78</strong>)取得<a>工学学士</a>，并且顺利毕业于<a>东莞理工 计算机软件工程专业</a>， 获得<strong>优秀本科毕业生</strong>。",new16:'[ 2022.06 ] 恭喜! 我的论文在<a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC22</a>中关于<Strong>无监督域适应第一人称动作识别</Strong>顺利被接收, 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下。 预印本和代码均可用. <a href="https://arxiv.org/abs/2207.03095">[ArXiv 预印本]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github代码]</a>',new17:'[ 2022.07 ] 我受邀参加今年<a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> 并参与 <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a> 演讲。<a>此处</a> 有相关描述。',new18:'[ 2022.07 ] 我们关于<Strong>知识迁移学习</Strong>的论文已经被今年的<Strong>ECCV 2022</Strong>正式接受!! 代码已经开源。<a href="https://github.com/dzy3/KCD">[Github 代码]</a>',new19:'[ 2022.08 ] 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下，我在今年的<Strong>BMVC 2022</Strong>上提交了一篇<Strong>基于自我中心视频中手部区域与第一人称动作识别相关的</Strong>论文。代码将会开源！！',new20:'[ 2022.08 ] 我非常希望我能尽快申请研究生和硕士，开始我的新项目:<Strong>EgoV: 从虚拟到现实</Strong>。<a href="https://github.com/dzy3/KCD">[Github 代码]</a><a href="https://github.com/dzy3/KCD">[项目页面]</a><a href="https://github.com/dzy3/KCD">[研究计划书]</a>'},biographyTitle:"个人经历",biography:{bio1:{introduce:"(2021.6-至今)  助理研究员. 指导教授为",mentor:"蔡 敏捷",brief1:"信息科学与工程学院, FPV Lab",brief2:"湖南大学"},bio2:{introduce:"(2018-至今)  计算机软件工程在读 (毕业于 2022.06)",brief1:"工业人工智能技术研究所 (IIAIT)",brief2:"东莞理工大学"}},exchangeTitle:"专业经验",exchangeSubtitle:"本人非常热衷于科研交流，以下为经常交流学习的大学：",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              清華大学\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.17\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.28\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.20\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: 世界大学排名ーーNo.29\n              </p>\n                '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              シンガポール国立大学（NUS）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.11\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.32\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.25\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              トロント大学（UofT）\n              </p> \n              <br><p style="font-size: 14.9px">\n              QS 2021: 世界大学排名ーーNo.26\n              </p>\n              <br><p style="font-size: 14.9px">\n              U.S. New : 世界大学排名ーーNo.17\n              </p>\n              <br><p style="font-size: 14.9px">\n              THE 2021: 世界大学排名ーーNo.18\n              </p>\n              <br><p style="font-size: 14.9px">\n              ARWU 2021: 世界大学排名ーーNo.23\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              ホンコン科技大学（HKUST）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.34\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.109\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.56\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. 湖南大学 (HNU)",workplace:"长沙, 中国",topic:"研究课题: 基于手部区域的第一人称动作识别",title:"助理研究员",supervisor:" 指导教授: 蔡 敏捷 教授 [湖南大学]"},{name:"2. 工业人工智能技术研究所 (IIAIT)",workplace:"东莞, 中国",topic:"研究课题: 数字图像处理",title:"助理研究员",supervisor:" 指导教授: 陈高教授 [清华大学]"},{name:"3. 哈尔滨工业大学 (HIT)",workplace:"深圳, 中国",topic:"研究课题: 视频分析与理解",title:"研究实习生",supervisor:" 指导教授: 廖清教授 [哈尔滨工业大学(深圳)]"},{name:"4. 多伦多大学 (UofT)",workplace:"多伦多, 加拿大",topic:"研究课题: 数学与机器学习",title:"项目学生",supervisor:" 指导教授: Lvy Wang教授 [多伦多大学]"}],researchTitle:"研究兴趣",overallField:"整体领域",researchOverInterest:["计算机视觉 (CV)","第一人称视觉 (FPV)","人机交互 (HCI),"],specialField:"特别兴趣",researchSpecialInterest:["1. 自我中心的视频理解和分析","2. 域适应与泛化","3. 行为识别","4. 手部区域分析","5. 知识迁移学习",".........................."],awardsTitle:"荣誉奖项",scholarship:"所获奖学金",scholar1:"1. 中华人民共和国国家奖学金",scholar1explain:"[中华人民共和国教育部]",scholar1supp:"(中国排名前0.1%的学生)",scholar2:"2. 岭南学术奖学金  [杰出的学术代表]",scholar3:"3. 2021年学年度一等奖奖学金   [年级GPA第一名，2021年]",scholar4:"4. 高伟光企业奖学金   [杰出的工程代表]",scholar5:"5. 2020年学年度一等奖奖学金   [年级GPA第一名，2020年]",scholar6:"6. 2019年学年度一等奖奖学金   [年级GPA第一名，2019年]",awards:[{subtitle:"奖励",content:["广东省优秀本科毕业生","优秀本科生的论文","美国数学建模竞赛国际二等奖","中国计算机学会AI视觉算法大赛 (排名13/2207)","中国人工智能电子设计大赛三等奖","新加坡国立大学荣誉奖","华为优秀开发者奖"]}],conferenceTitle:"论文发表",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022: Team HNU-FPV Report",author:'<a href="#">Nie Lin</a>, Minjie Cai*',date:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshop, 2022",arixv:"xxxx",code:"xxxxx"},{name:"Knowledge Condensation Distillation",author:'Chenxin Li, Mingbao Lin, Zhiyuan Ding, <a href="#">Nie Lin</a>, Yihong Zhuang, Yue Huang*',date:"European Conference on Computer Vision (ECCV), 2022",arixv:"xxxx",code:"xxxxx"}],journalTitle:"期刊论文",journalPublication:[{name:"暂无"}],patentTitle:"发表专利",patent:[{name:"基于模拟信号处理的人机交互感知设备",author:'<a href="#">林涅</a>, 刘婵梓博士, 黎浩锋, 邹世豪, 李俊裕',number:"CN 202022246705.5"}],copyrghtTitle:"软件著作",softwareCopyrght:[{name:"日文邮政支付票据 OCR识别安卓客户端App（日文邮政票 OCR App）",Number:"软著登字第 A0003976号"},{name:"基于人工智能的视频版权保护系统",Number:"软著登字第 4840268号"}],projectsTitle:"项目经验",projectsHightLight:"高亮",projectsNote:" 表示最近开展的项目。",recentlyProjects:[{name:"EgoV: 一个全新的跨越真实和虚拟的以自我中心视频的数据集",author:"<strong>！！作为一个全新的长期项目，将会在我硕士阶段展开！！</strong>",match:"",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"基于自中心视频手部区域的无监督域适应第一人称动作识别",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"基于迁移学习的知识浓缩蒸馏",author:"李 宸鑫, 林 明宝, <strong>林 涅</strong>, 庄毅鸿, 黄悦",match:"厦门大学 & 湖南大学",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"第一人称视角下的数据集采集 (通过头戴式摄像头)",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",paper:"",projectPage:"",code:"",video:"[Video]"}],pastProjects:[{name:"基于扩张残差收缩网络的数字图像去噪",author:"<strong>林 涅</strong>, 陈 高, 周 清峰, 刘 婵梓",match:"工业人工智能技术研究所 (IIAIT)",match2:"",paper:"[Paper]",projectPage:"",code:"",video:""},{name:"多模态视频分析与理解",author:"<strong>林 涅</strong>, 郭 凡, 王 杰, 丁 烨, 廖 清",match:"哈尔滨工业大学 (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"基于OpenMV机器视觉的手球动作识别控制系统",author:"<strong>林 涅</strong>, 王 斌, 周 清峰",match:"中国人工智能电子设计大赛",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"参与基金",scientificFund:[{name:'<a href="#">国家自然科学基金</a>',match:"国家自然科学基金号：No. 61971138"},{name:"广东省基础与应用基础研究资助项目",match:"项目基金号：No. 2019A1515111149"},{name:"广东省高等教育创新与高校发展工程",match:"工程基金号：No. 2020ZDZX3047"}],footer:{period:"© 2018 - 2021   林涅",lastUpdated:"上次更新: 2021年8月16日"}};var bt=wt;o["a"].use(gt["a"]);var yt=new gt["a"].Store({state:{words:ut,dictionary:{en:ut,zh:bt,jp:mt}},mutations:{SET_LANGUAGE(e,t){e.words=e.dictionary[t]}},actions:{setLanguage({commit:e},t){e("SET_LANGUAGE",t)}},getters:{words(e){return e.words}},modules:{}}),vt=(n("63bf"),n("ecee")),_t=n("c074"),Ct=n("b702"),Pt=n("f2d1"),xt=n("ad3d");vt["c"].add(_t["a"],Ct["a"],Pt["a"]),o["a"].component("font-awesome-icon",xt["a"]),o["a"].component("font-awesome-layers",xt["b"]),o["a"].component("font-awesome-layers-text",xt["c"]),o["a"].config.productionTip=!1,new o["a"]({store:yt,render:e=>e(dt)}).$mount("#app")},cfa2:function(e,t,n){e.exports=n.p+"img/xx.5a35d7e2.png"},d4d5:function(e,t,n){var o={"./0.gif":"0db5","./1.gif":"2d4f","./2.gif":"4382","./3.gif":"d6b6"};function r(e){var t=i(e);return n(t)}function i(e){if(!n.o(o,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return o[e]}r.keys=function(){return Object.keys(o)},r.resolve=i,e.exports=r,r.id="d4d5"},d6b6:function(e,t,n){e.exports=n.p+"img/3.b8a7d661.gif"},e052:function(e,t,n){},e429:function(e,t,n){e.exports=n.p+"img/image.a6041b50.png"},e471:function(e,t,n){"use strict";n("7037")},ed26:function(e,t,n){}});
//# sourceMappingURL=app.d4946676.js.map